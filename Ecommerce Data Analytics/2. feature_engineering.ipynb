{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "## Overview\n",
    "This notebook creates derived features for customer and product analysis.\n",
    "\n",
    "## Features Created\n",
    "\n",
    "### Transaction-Level Features\n",
    "| Feature | Formula | Purpose |\n",
    "|---------|---------|--------|\n",
    "| TotalAmount | Quantity x UnitPrice | Order line value |\n",
    "| PriceCategory | Quantile binning | Price tier analysis |\n",
    "| IsCancellation | InvoiceNo starts with 'C' | Return identification |\n",
    "\n",
    "### Time-Based Features\n",
    "| Feature | Derivation | Purpose |\n",
    "|---------|------------|--------|\n",
    "| DayOfWeek | From InvoiceDate | Day patterns |\n",
    "| Month | From InvoiceDate | Seasonal trends |\n",
    "| Hour | From InvoiceDate | Time-of-day patterns |\n",
    "| IsWeekend | Saturday/Sunday flag | Weekend vs weekday |\n",
    "\n",
    "### Customer-Level Features (RFM-adjacent)\n",
    "| Feature | Calculation | Purpose |\n",
    "|---------|-------------|--------|\n",
    "| CustomerLifetimeValue | Sum of TotalAmount per customer | Customer value ranking |\n",
    "| AvgOrderValue | Mean TotalAmount per customer | Spending behavior |\n",
    "| PurchaseFrequency | Count of unique invoices | Loyalty indicator |\n",
    "| IsReturningCustomer | >1 purchase flag | Retention analysis |\n",
    "\n",
    "### Product-Level Features\n",
    "| Feature | Calculation | Purpose |\n",
    "|---------|-------------|--------|\n",
    "| ProductPopularity | Sum of quantity per product | Demand ranking |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transaction_features(df):\n",
    "    \"\"\"\n",
    "    Create transaction-level derived features.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with Quantity, UnitPrice, InvoiceNo columns\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with new features added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Total transaction value\n",
    "    df['TotalAmount'] = (df['Quantity'] * df['UnitPrice']).round(2)\n",
    "    \n",
    "    # Price category using quantile binning\n",
    "    # Only bin positive prices to avoid issues with free items\n",
    "    df['PriceCategory'] = pd.qcut(\n",
    "        df['UnitPrice'].clip(lower=0.01),  # Avoid zero prices in binning\n",
    "        q=3, \n",
    "        labels=['Low', 'Medium', 'High']\n",
    "    )\n",
    "    \n",
    "    # Identify cancellations/returns (InvoiceNo starts with 'C')\n",
    "    df['IsCancellation'] = df['InvoiceNo'].astype(str).str.startswith('C').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"\n",
    "    Create time-based features from InvoiceDate.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with InvoiceDate column (datetime)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with time features added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure datetime type\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    \n",
    "    # Extract time components\n",
    "    df['DayOfWeek'] = df['InvoiceDate'].dt.day_name()\n",
    "    df['Month'] = df['InvoiceDate'].dt.month_name()\n",
    "    df['MonthNum'] = df['InvoiceDate'].dt.month  # For proper sorting\n",
    "    df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "    df['YearMonth'] = df['InvoiceDate'].dt.to_period('M')  # For trend analysis\n",
    "    \n",
    "    # Weekend flag - using vectorized isin() instead of apply(lambda)\n",
    "    # This is 10-100x faster than apply(lambda)\n",
    "    df['IsWeekend'] = df['DayOfWeek'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_customer_features(df):\n",
    "    \"\"\"\n",
    "    Create customer-level aggregated features.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with CustomerID, TotalAmount, InvoiceNo columns\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with customer features merged in\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate all customer metrics in a single groupby operation\n",
    "    # This is more efficient than multiple separate groupby + merge operations\n",
    "    customer_metrics = df.groupby('CustomerID').agg(\n",
    "        CustomerLifetimeValue=('TotalAmount', 'sum'),\n",
    "        AvgOrderValue=('TotalAmount', 'mean'),\n",
    "        PurchaseFrequency=('InvoiceNo', 'nunique'),\n",
    "        TotalTransactions=('InvoiceNo', 'count'),\n",
    "        FirstPurchase=('InvoiceDate', 'min'),\n",
    "        LastPurchase=('InvoiceDate', 'max')\n",
    "    ).round(2).reset_index()\n",
    "    \n",
    "    # Returning customer flag (more than 1 unique invoice)\n",
    "    customer_metrics['IsReturningCustomer'] = (customer_metrics['PurchaseFrequency'] > 1).astype(int)\n",
    "    \n",
    "    # Merge back to transaction data - single merge instead of multiple\n",
    "    df = df.merge(customer_metrics, on='CustomerID', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_product_features(df):\n",
    "    \"\"\"\n",
    "    Create product-level features.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with Description/StockCode and Quantity columns\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with product features added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Product popularity based on total quantity sold\n",
    "    # Using transform() to broadcast back to original DataFrame\n",
    "    df['ProductPopularity'] = df.groupby('StockCode')['Quantity'].transform('sum')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering in sequence\n",
    "print(\"Creating transaction features...\")\n",
    "df = create_transaction_features(df)\n",
    "\n",
    "print(\"Creating time features...\")\n",
    "df = create_time_features(df)\n",
    "\n",
    "print(\"Creating product features...\")\n",
    "df = create_product_features(df)\n",
    "\n",
    "print(\"Creating customer features...\")\n",
    "df = create_customer_features(df)\n",
    "\n",
    "print(f\"\\nFeature engineering complete. Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review new columns\n",
    "print(\"Columns after feature engineering:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Check\n",
    "\n",
    "Verify feature values make sense before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== Numeric Feature Summary ===\")\n",
    "numeric_cols = ['Quantity', 'UnitPrice', 'TotalAmount', 'ProductPopularity', \n",
    "                'CustomerLifetimeValue', 'AvgOrderValue', 'PurchaseFrequency']\n",
    "df[numeric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify anomalies\n",
    "anomalies = {\n",
    "    'Negative Quantity': (df['Quantity'] < 0).sum(),\n",
    "    'Negative TotalAmount': (df['TotalAmount'] < 0).sum(),\n",
    "    'Zero UnitPrice': (df['UnitPrice'] == 0).sum(),\n",
    "    'Negative CLV': (df['CustomerLifetimeValue'] < 0).sum(),\n",
    "    'Negative ProductPopularity': (df['ProductPopularity'] < 0).sum(),\n",
    "    'Cancellations': df['IsCancellation'].sum()\n",
    "}\n",
    "\n",
    "print(\"=== Anomaly Detection ===\")\n",
    "for name, count in anomalies.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"{name}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Explanation\n",
    "\n",
    "| Anomaly | Cause | Treatment |\n",
    "|---------|-------|----------|\n",
    "| Negative Quantity | Returns/cancellations (Invoice starts with 'C') | Keep for analysis, filter for sales-only views |\n",
    "| Negative TotalAmount | Result of negative quantity x price | Same as above |\n",
    "| Zero UnitPrice | Free items, samples, or promotional giveaways | Keep - legitimate transactions |\n",
    "| Negative CLV | Customer with net refunds > purchases | Flag for investigation |\n",
    "| Negative ProductPopularity | Products with more returns than sales | Clip to 0 for popularity ranking |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate customers with negative CLV\n",
    "negative_clv_customers = df[df['CustomerLifetimeValue'] < 0]['CustomerID'].unique()\n",
    "print(f\"Customers with negative CLV: {len(negative_clv_customers)}\")\n",
    "print(f\"Customer IDs: {negative_clv_customers}\")\n",
    "\n",
    "# Show their transaction history\n",
    "if len(negative_clv_customers) > 0:\n",
    "    print(\"\\nSample transactions for customer with negative CLV:\")\n",
    "    sample_cust = negative_clv_customers[0]\n",
    "    print(df[df['CustomerID'] == sample_cust][['InvoiceNo', 'Description', 'Quantity', 'UnitPrice', 'TotalAmount']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Analysis-Ready Dataset\n",
    "\n",
    "For most analyses, we want to exclude:\n",
    "- Cancellations/returns (negative quantities)\n",
    "- Zero-price items (can't calculate meaningful averages)\n",
    "\n",
    "We'll create a \"clean\" version while preserving the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filtered version for analysis (excluding returns and zero-price)\n",
    "df_sales_only = df[\n",
    "    (df['Quantity'] > 0) & \n",
    "    (df['TotalAmount'] > 0) & \n",
    "    (df['UnitPrice'] > 0)\n",
    "].copy()\n",
    "\n",
    "# Fix ProductPopularity - clip negative values to 0\n",
    "df_sales_only['ProductPopularity'] = df_sales_only['ProductPopularity'].clip(lower=0)\n",
    "\n",
    "print(f\"Full dataset: {len(df):,} rows\")\n",
    "print(f\"Sales only (no returns/free items): {len(df_sales_only):,} rows\")\n",
    "print(f\"Removed: {len(df) - len(df_sales_only):,} rows ({(len(df) - len(df_sales_only))/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate customer metrics on sales-only data for cleaner analysis\n",
    "# (Original CLV includes returns which can distort analysis)\n",
    "sales_customer_metrics = df_sales_only.groupby('CustomerID').agg(\n",
    "    CLV_SalesOnly=('TotalAmount', 'sum'),\n",
    "    AvgOrderValue_SalesOnly=('TotalAmount', 'mean')\n",
    ").round(2).reset_index()\n",
    "\n",
    "df_sales_only = df_sales_only.merge(sales_customer_metrics, on='CustomerID', how='left')\n",
    "\n",
    "print(\"Added recalculated customer metrics (excluding returns):\")\n",
    "print(\"- CLV_SalesOnly\")\n",
    "print(\"- AvgOrderValue_SalesOnly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no negative values in sales-only dataset\n",
    "print(\"=== Sales-Only Dataset Validation ===\")\n",
    "print(f\"Min Quantity: {df_sales_only['Quantity'].min()}\")\n",
    "print(f\"Min TotalAmount: {df_sales_only['TotalAmount'].min()}\")\n",
    "print(f\"Min CLV_SalesOnly: {df_sales_only['CLV_SalesOnly'].min()}\")\n",
    "print(f\"Min ProductPopularity: {df_sales_only['ProductPopularity'].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final column overview\n",
    "print(\"=== Final Dataset Schema ===\")\n",
    "print(f\"\\nShape: {df_sales_only.shape}\")\n",
    "print(f\"\\nColumn types:\")\n",
    "print(df_sales_only.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_only.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the SALES-ONLY dataset (cleaned, no returns)\n",
    "# This fixes the original bug where the wrong dataframe was exported\n",
    "df_sales_only.to_csv('data_final.csv', index=False)\n",
    "\n",
    "print(\"Exported: data_final.csv\")\n",
    "print(f\"Rows: {len(df_sales_only):,}\")\n",
    "print(f\"Columns: {len(df_sales_only.columns)}\")\n",
    "\n",
    "print(\"\\n=== Feature Engineering Summary ===\")\n",
    "print(\"Transaction features: TotalAmount, PriceCategory, IsCancellation\")\n",
    "print(\"Time features: DayOfWeek, Month, MonthNum, Hour, YearMonth, IsWeekend\")\n",
    "print(\"Customer features: CustomerLifetimeValue, AvgOrderValue, PurchaseFrequency, IsReturningCustomer\")\n",
    "print(\"Product features: ProductPopularity\")\n",
    "print(\"Clean metrics: CLV_SalesOnly, AvgOrderValue_SalesOnly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
